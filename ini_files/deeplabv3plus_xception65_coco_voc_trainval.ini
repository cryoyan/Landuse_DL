#the parameter file for deep learning network setting

# note:
#1. deeplabv3_pascal_train_aug_2018_01_04.tar.gz has been trained on PASCAL dataset, so it has 21 classes,
#    the code will set NUM_CLASSES_noBG to 21. We still can use class 0 and 1, other classes are nan.
#2. As suggested, need to set base_learning_rate to very small, such as 0.0001, otherwise,
#   end with "Loss is inf or nan" and crash

##############################################################

tf_research_dir = ~/codes/PycharmProjects/tensorflow/yghlc_tf_model/research
tf1x_python  = ~/programs/miniconda3/envs/tf1.14/bin/python

# defined the pre-trained model
pre_trained_model_folder = ~/Data/deeplab/v3+/pre-trained_model
pre_trained_model_url = http://download.tensorflow.org/models/deeplabv3_pascal_trainval_2018_01_04.tar.gz
TF_INIT_CKPT = deeplabv3_pascal_trainval_2018_01_04.tar.gz
tf_initial_checkpoint = deeplabv3_pascal_trainval/model.ckpt
model_variant = xception_65

## training parameter
batch_size=8

# the number of iteration
iteration_num=100

#base_learning_rate
# Use 0.007 when training on PASCAL augmented training set, train_aug. When
# fine-tuning on PASCAL trainval set, use learning rate=0.0001. (from deeplab train.py)
base_learning_rate=0.0001

# For `xception_65`, use atrous_rates = [12, 24, 36] if output_stride = 8, or
# rates = [6, 12, 18] if output_stride = 16. Note one could use different
# atrous_rates/output_stride during training/evaluation. (from deeplab train.py)
train_output_stride=16
train_atrous_rates1=6
train_atrous_rates2=12
train_atrous_rates3=18

inf_output_stride=8
inf_atrous_rates1=12
inf_atrous_rates2=24
inf_atrous_rates3=36

# decoder output stride
decoder_output_stride = 4

# 1 for export multi scale frozen inference graph, 0 for single-scale
export_multi_scale = 1


# batch size for inference
# (After update DeepLab repo on 18 Jan 2021, the export_model.py go back to original version which only accepts inf batch size as 1)
inf_batch_size=1
##############################################################

