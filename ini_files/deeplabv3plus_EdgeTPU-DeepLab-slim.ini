#the parameter file for deep learning network setting


# #1. deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz is trained with 21 classes,
#    the code will set NUM_CLASSES_noBG to 21. We still can use class 0 and 1, other classes are nan.
# 2. No atrous_rates
# 3. with two P100 GPUs (16*2 GB memory), set batch size as large as possible.
# 4. adjust the learning as large as possible (no cash with loss nan)
##############################################################

tf_research_dir = ~/codes/PycharmProjects/tensorflow/yghlc_tf_model/research
tf1x_python  = ~/programs/miniconda3/envs/tf1.14/bin/python

# defined the pre-trained model, trained on imagenet
pre_trained_model_folder = ~/Data/deeplab/v3+/pre-trained_model
pre_trained_model_url = http://download.tensorflow.org/models/edgetpu-deeplab-slim_2020_03_09.tar.gz
TF_INIT_CKPT = edgetpu-deeplab-slim_2020_03_09.tar.gz
tf_initial_checkpoint = edgetpu-deeplab-slim/model.ckpt
model_variant = mobilenet_edgetpu

## training parameter
batch_size=32

# the number of iteration
iteration_num=100

# depth_multiplier default is 1.0
depth_multiplier = 0.75

#base_learning_rate
# Use 0.007 when training on PASCAL augmented training set, train_aug. When
# fine-tuning on PASCAL trainval set, use learning rate=0.0001. (from deeplab train.py)
base_learning_rate=0.0001

# For `xception_65`, use atrous_rates = [12, 24, 36] if output_stride = 8, or
# rates = [6, 12, 18] if output_stride = 16. Note one could use different
# atrous_rates/output_stride during training/evaluation. (from deeplab train.py)
train_output_stride=16
#train_atrous_rates1=6
#train_atrous_rates2=12
#train_atrous_rates3=18

inf_output_stride=16
#inf_atrous_rates1=12
#inf_atrous_rates2=24
#inf_atrous_rates3=36

## decoder output stride (no decoder modules)
#decoder_output_stride = 8

aspp_convs_filters=128

## the following para also needed by mobilenet_v3, we set then in the code
#--image_pooling_crop_size=769,769  # change to the crop size in main_para.ini
#--image_pooling_stride=4,5
#--add_image_level_feature=1
#--aspp_with_concat_projection=0
#--aspp_with_squeeze_and_excitation=1
#--decoder_use_sum_merge=1
#--decoder_filters=19
#--decoder_output_is_logits=1
#--image_se_uses_qsigmoid=1



# 1 for export multi scale frozen inference graph, 0 for single-scale
export_multi_scale = 1


# batch size for inference
# (After update DeepLab repo on 18 Jan 2021, the export_model.py go back to original version which only accepts inf batch size as 1)
inf_batch_size=1
##############################################################

